# -*- coding: utf-8 -*-
"""Pipeline.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dfVUwROkusSGpHu45dWBzIX1aHM4xxIK
"""

import pandas as pd
from sklearn.metrics import  roc_auc_score, accuracy_score,   recall_score, classification_report, confusion_matrix
from sklearn.model_selection import train_test_split
import numpy as np
from sklearn.model_selection import train_test_split,cross_val_score
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.linear_model import LogisticRegression

df_original=pd.read_csv("WA_Fn-UseC_-Telco-Customer-Churn.csv")
df=df_original.copy()

# Replace whitespace or empty strings with NaN
df["TotalCharges"] = pd.to_numeric(df["TotalCharges"], errors='coerce')

# Drop rows where `TotalCharges` is NaN
df = df.dropna(subset=["TotalCharges"])

df["Churn"]=df["Churn"].map({'No':0, "Yes":1})
# Target
y=df['Churn'].copy()

# Deciding Factors
deciding_factors = ['Partner', 'Dependents', 'OnlineSecurity', 'OnlineBackup',
                    'DeviceProtection', 'TechSupport', 'Contract', 'PaperlessBilling',
                    'PaymentMethod', 'tenure', 'MonthlyCharges', 'TotalCharges']

X=df[deciding_factors].copy()




#print(X["TotalCharges"]).dtype
# Encoding
cat_factors = ['Partner', 'Dependents', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'Contract', 'PaperlessBilling', 'PaymentMethod']
num_factors = ['tenure', 'MonthlyCharges', 'TotalCharges']

# Dropna
X=X.dropna()

# X_test_final_set, y_test_final_set --> they will be used for final testing and model evaluation
X_train,X_test_final_set, y_train, y_test_final_set=train_test_split(X,y, test_size=0.2, random_state=42, stratify=y,shuffle=True)

# Dividing X_train,y_train into actual training set and development test set
X_train_actual,X_test_dev_set, y_train_actual, y_test_dev_set=train_test_split(X_train,y_train, test_size=0.2, random_state=42, stratify=y_train,shuffle=True)

num_pipeline=Pipeline([
    ('imputer',SimpleImputer(strategy='median')),
    ('std_scaler',StandardScaler())
])

cat_pipeline=Pipeline([
    ('imputer',SimpleImputer(strategy='most_frequent')),
    ('one_hot_encoder',OneHotEncoder(sparse_output=False,handle_unknown='ignore'))
])

# column transformer
preprocessing=ColumnTransformer([
    ('num',num_pipeline,num_factors),
    ('cat',cat_pipeline,cat_factors)
])

# final pipeline
Final_pipeline=Pipeline([
    ('preprocessing',preprocessing),
    ('model',LogisticRegression(C=0.010022268827315503,penalty='l1',solver='liblinear',class_weight='balanced'))])
Final_pipeline.fit(X_train_actual,y_train_actual)

y_pred=Final_pipeline.predict(X_test_dev_set)
y_pred_proba=Final_pipeline.predict_proba(X_test_dev_set)[:,1]

# Evaluation
print(classification_report(y_test_dev_set,y_pred))
print(roc_auc_score(y_test_dev_set,y_pred_proba))
print(accuracy_score(y_test_dev_set,y_pred))

# save the pipeline
import joblib
joblib.dump(Final_pipeline,'final_pipeline.pkl')

# Loading and checking the performance in the final test set
final_pipeline=joblib.load('final_pipeline.pkl')
y_pred_final=final_pipeline.predict(X_test_final_set)
y_pred_proba_final=final_pipeline.predict_proba(X_test_final_set)[:,1]
print(classification_report(y_test_final_set,y_pred_final))
print(roc_auc_score(y_test_final_set,y_pred_proba_final))
print(accuracy_score(y_test_final_set,y_pred_final))  # Since the main focus was to improve the recall score of class 1 (churn), the performance is satisfactory.