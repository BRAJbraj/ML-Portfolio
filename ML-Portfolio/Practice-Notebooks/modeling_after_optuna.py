# -*- coding: utf-8 -*-
"""Modeling_After_optuna.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1isfACvVg0A_o-el6utj0mjaaALUEj37F
"""

! pip install optuna

!pip install XGBoost

import pandas as pd
from sklearn.model_selection import train_test_split,cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from  xgboost import XGBClassifier
import optuna

df_original=pd.read_csv("WA_Fn-UseC_-Telco-Customer-Churn.csv")
df=df_original.copy()

# Replace whitespace or empty strings with NaN
df["TotalCharges"] = pd.to_numeric(df["TotalCharges"], errors='coerce')

# Drop rows where `TotalCharges` is NaN
df = df.dropna(subset=["TotalCharges"])

df["Churn"]=df["Churn"].map({'No':0, "Yes":1})
# Target
y=df['Churn'].copy()

# Deciding Factors
deciding_factors = ['Partner', 'Dependents', 'OnlineSecurity', 'OnlineBackup',
                    'DeviceProtection', 'TechSupport', 'Contract', 'PaperlessBilling',
                    'PaymentMethod', 'tenure', 'MonthlyCharges', 'TotalCharges']

X=df[deciding_factors].copy()




#print(X["TotalCharges"]).dtype
# Encoding
cat_factors = ['Partner', 'Dependents', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'Contract', 'PaperlessBilling', 'PaymentMethod']
num_factors = ['tenure', 'MonthlyCharges', 'TotalCharges']

# Dropna
X=X.dropna()
# One-hot encode multi-category vars (e.g., Contract, PaymentMethod)
X_encoded = pd.get_dummies(X, columns=cat_factors, drop_first=True) # Encoded features

#print(X_encoded)

# X_test_final_set, y_test_final_set --> they will be used for final testing and model evaluation
X_train,X_test_final_set, y_train, y_test_final_set=train_test_split(X_encoded,y, test_size=0.2, random_state=42, stratify=y,shuffle=True)


# Dividing X_train,y_train into actual training set and development test set
X_train_actual,X_test_dev_set, y_train_actual, y_test_dev_set=train_test_split(X_train,y_train, test_size=0.2, random_state=42, stratify=y_train,shuffle=True)


X_train_actual.isnull().sum()
X_train_actual

from sklearn.preprocessing import StandardScaler


scaler = StandardScaler()

# Fit and transform the training data
X_train_scaled = scaler.fit_transform(X_train_actual)
X_test_dev_set_scaled=scaler.transform(X_test_dev_set) # Use this at development stage
X_test_final_set_scaled=scaler.transform(X_test_final_set)  # Use this for final evaluation

import optuna
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from xgboost import XGBClassifier
from sklearn.model_selection import cross_val_score

# Define the objective function
def objective(trial):
    # Suggest a model type
    model_name = trial.suggest_categorical("model", ["RandomForestClassifier", "LogisticRegression", "XGBClassifier"])

    # Hyperparameter tuning for RandomForestClassifier
    if model_name == "RandomForestClassifier":
        n_estimators = trial.suggest_int("n_estimators", 100, 200)
        max_depth = trial.suggest_int("max_depth", 5, 10)
        min_samples_leaf = trial.suggest_int("min_samples_leaf", 5, 15)

        model = RandomForestClassifier(
            n_estimators=n_estimators,
            max_depth=max_depth,
            min_samples_leaf=min_samples_leaf,
            random_state=50
        )

    # Hyperparameter tuning for LogisticRegression
    elif model_name == "LogisticRegression":
        C = trial.suggest_float("C", 0.01, 10, log=True)
        penalty = trial.suggest_categorical("penalty", ["l1", "l2", "elasticnet"])
        solver = trial.suggest_categorical("solver", ["newton-cg", "lbfgs", "liblinear", "sag", "saga"])
        class_weight = trial.suggest_categorical("class_weight", ["balanced", None])

        # Ensure the penalty and solver combination is valid
        if penalty == "l1" and solver not in ["liblinear", "saga"]:
            return float("-inf")  # Skip invalid combinations
        if penalty == "elasticnet" and solver != "saga":
            return float("-inf")  # Skip invalid combinations

        model = LogisticRegression(
            C=C,
            penalty=penalty,
            solver=solver,
            class_weight=class_weight,
            random_state=50,
            max_iter=1000
        )

    # Hyperparameter tuning for XGBClassifier
    elif model_name == "XGBClassifier":
        n_estimators = trial.suggest_int("n_estimators", 100, 200)
        max_depth = trial.suggest_int("max_depth", 5, 10)
        min_child_weight = trial.suggest_int("min_child_weight", 1, 10)
        gamma = trial.suggest_float("gamma", 0, 5)
        subsample = trial.suggest_float("subsample", 0.5, 1.0)

        model = XGBClassifier(
            n_estimators=n_estimators,
            max_depth=max_depth,
            min_child_weight=min_child_weight,
            gamma=gamma,
            subsample=subsample,
            random_state=50
        )

    # Evaluate the model using cross-validation
    try:
        score = cross_val_score(model, X_train_scaled, y_train_actual, cv=4, scoring="recall", error_score='raise').mean()
    except ValueError as e:
        # Handle model misconfiguration gracefully
        score = float("-inf")

    return score

# Create the study
study = optuna.create_study(direction="maximize", sampler=optuna.samplers.TPESampler(seed=50))
study.optimize(objective, n_trials=350)

# Print the best result
print("Best trial:")
print(study.best_trial.params)  # Suggest that logisticregression is the best algorithm for the churn dataset.
print(study.best_trial.value)



"""**Final Model**"""

from sklearn.linear_model import LogisticRegression

# Modeling
final_model = LogisticRegression(
    C=0.010022268827315503,      # Inverse regularization strength (small value means stronger regularization)
    penalty='l1',                 # L1 penalty for sparsity (good for feature selection)
    solver='liblinear',           # Suitable for L1 and smaller datasets
    class_weight='balanced'       # Handles class imbalance, which aligns with your recall focus
)                                                                                                                 # This is the best model so far.

# Fit the model (ensure X_train_scaled and y_train_actual are defined and preprocessed)
final_model.fit(X_train_scaled, y_train_actual)
scores = cross_val_score(final_model, X_train_scaled,y_train_actual, cv=5)

# Prediction
y_pred = final_model.predict(X_test_final_set_scaled)
y_pred_proba=final_model.predict_proba(X_test_final_set_scaled)[:,1]


# Also for dev set
y_pred_dev=final_model.predict(X_test_dev_set_scaled)
y_pred_proba_dev=final_model.predict_proba(X_test_dev_set_scaled)[:,1]
print(classification_report(y_test_dev_set,y_pred_dev))
print(roc_auc_score(y_test_dev_set,y_pred_proba_dev))

#Eva;uation
from sklearn.metrics import  roc_auc_score,classification_report
print(classification_report(y_test_final_set,y_pred))
print(roc_auc_score(y_test_final_set,y_pred_proba))

final_model.coef_

# Lets train the model with X_train and y_train and test on x_test_final_set and y_test_final_test
X_train_scaled=scaler.fit_transform(X_train)
X_test_final_set_scaled=scaler.transform(X_test_final_set)
final_model.fit(X_train_scaled,y_train)
y_pred=final_model.predict(X_test_final_set_scaled)
y_pred_proba=final_model.predict_proba(X_test_final_set_scaled)[:,1]

# Evaluation
from sklearn.metrics import  roc_auc_score,classification_report
print(classification_report(y_test_final_set,y_pred))
print(roc_auc_score(y_test_final_set,y_pred_proba))

# Lets check for the overfitting by comparing classification report  score on training set and test set
y_pred_train=final_model.predict(X_train_scaled)
y_pred_proba_train=final_model.predict_proba(X_train_scaled)[:,1]
print(y_pred_proba_train.shape[0])
print(y_pred_proba.shape[0])
print(classification_report(y_train,y_pred_train))

"""Not overfitting

"""

