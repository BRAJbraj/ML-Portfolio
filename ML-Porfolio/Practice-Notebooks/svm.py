# -*- coding: utf-8 -*-
"""SVM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1umlXIUdxmiMxj7XGHkw0srdVqM9b-Tc2
"""

! pip install optuna

import pandas as pd
from sklearn.model_selection import train_test_split,cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import  roc_auc_score,classification_report
import optuna
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler

df_original=pd.read_csv("WA_Fn-UseC_-Telco-Customer-Churn.csv")
df=df_original.copy()

# Replace whitespace or empty strings with NaN
df["TotalCharges"] = pd.to_numeric(df["TotalCharges"], errors='coerce')

# Drop rows where `TotalCharges` is NaN
df = df.dropna(subset=["TotalCharges"])

df["Churn"]=df["Churn"].map({'No':0, "Yes":1})
# Target
y=df['Churn'].copy()

# Deciding Factors
deciding_factors = ['Partner', 'Dependents', 'OnlineSecurity', 'OnlineBackup',
                    'DeviceProtection', 'TechSupport', 'Contract', 'PaperlessBilling',
                    'PaymentMethod', 'tenure', 'MonthlyCharges', 'TotalCharges']

X=df[deciding_factors].copy()




#print(X["TotalCharges"]).dtype
# Encoding
cat_factors = ['Partner', 'Dependents', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'Contract', 'PaperlessBilling', 'PaymentMethod']
num_factors = ['tenure', 'MonthlyCharges', 'TotalCharges']

# Dropna
X=X.dropna()
# One-hot encode multi-category vars (e.g., Contract, PaymentMethod)
X_encoded = pd.get_dummies(X, columns=cat_factors, drop_first=True) # Encoded features

#print(X_encoded)

# X_test_final_set, y_test_final_set --> they will be used for final testing and model evaluation
X_train,X_test_final_set, y_train, y_test_final_set=train_test_split(X_encoded,y, test_size=0.2, random_state=42, stratify=y,shuffle=True)


# Dividing X_train,y_train into actual training set and development test set
X_train_actual,X_test_dev_set, y_train_actual, y_test_dev_set=train_test_split(X_train,y_train, test_size=0.2, random_state=42, stratify=y_train,shuffle=True)


X_train_actual.isnull().sum()
X_train_actual

from sklearn.preprocessing import StandardScaler


scaler = StandardScaler()

# Fit and transform the training data
X_train_scaled = scaler.fit_transform(X_train_actual)
X_test_dev_set_scaled=scaler.transform(X_test_dev_set) # Use this at development stage
X_test_final_set_scaled=scaler.transform(X_test_final_set)  # Use this for final evaluation

def objective(trial):
  kernel=trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])
  C=trial.suggest_float('C', 0.001, 100, log=True)
  gamma=trial.suggest_categorical('gamma', ['scale', 'auto'])
  class_weight=trial.suggest_categorical('class_weight', ['balanced', None])


  model=SVC(kernel=kernel, C=C, gamma=gamma, class_weight=class_weight)

  score=cross_val_score(model, X_train_scaled, y_train_actual, cv=5, scoring='recall', )

  return score.mean()

study=optuna.create_study(direction='maximize',sampler=optuna.samplers.TPESampler(seed=50))
study.optimize(objective, n_trials=50)

study.best_params
study.best_trial.value  # This model is far more better than logistic regression.

# Lets change the number of trials to get some more score
def objective(trial):
  kernel=trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])
  C=trial.suggest_float('C', 0.001, 100, log=True)
  gamma=trial.suggest_categorical('gamma', ['scale', 'auto'])
  class_weight=trial.suggest_categorical('class_weight', ['balanced', None])


  model=SVC(kernel=kernel, C=C, gamma=gamma, class_weight=class_weight,probability=True)

  score=cross_val_score(model, X_train_scaled, y_train_actual, cv=5, scoring='recall', )

  return score.mean()

study=optuna.create_study(direction='maximize',sampler=optuna.samplers.TPESampler(seed=50))
study.optimize(objective, n_trials=100)

study.best_trial.value
study.best_params

# Modelling with above parameters
model_svc=SVC(**study.best_params)
model_svc.fit(X_train_scaled, y_train_actual)

# Prediction
y_pred=model_svc.predict(X_test_dev_set_scaled)
y_pred_proba=model_svc(probabilities=True).predict(X_test_dev_set_scaled)[:,1]

# Evaluation
print(classification_report(y_test_dev_set, y_pred))
print(roc_auc_score(y_test_dev_set, y_pred_proba))