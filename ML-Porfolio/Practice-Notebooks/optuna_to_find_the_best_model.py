# -*- coding: utf-8 -*-
"""Optuna_to_find_the_best_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rEVFigTA2qFw-bw-lLrGFhLKW3LNLjiv
"""



"""Most of the times, we are unsure about the Ml algorithms to use for the ML tasks. For the churn data set, we can use LogisticRegression, RandomForestClassifier and XGBClassifier. To find the best algorithm we can use optuna."""

! pip install optuna

!pip install XGBoost

import pandas as pd
from sklearn.model_selection import train_test_split,cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from  xgboost import XGBClassifier
import optuna

df_original=pd.read_csv("WA_Fn-UseC_-Telco-Customer-Churn.csv")
df=df_original.copy()

# Replace whitespace or empty strings with NaN
df["TotalCharges"] = pd.to_numeric(df["TotalCharges"], errors='coerce')

# Drop rows where `TotalCharges` is NaN
df = df.dropna(subset=["TotalCharges"])

df["Churn"]=df["Churn"].map({'No':0, "Yes":1})
# Target
y=df['Churn'].copy()

# Deciding Factors
deciding_factors = ['Partner', 'Dependents', 'OnlineSecurity', 'OnlineBackup',
                    'DeviceProtection', 'TechSupport', 'Contract', 'PaperlessBilling',
                    'PaymentMethod', 'tenure', 'MonthlyCharges', 'TotalCharges']

X=df[deciding_factors].copy()




#print(X["TotalCharges"]).dtype
# Encoding
cat_factors = ['Partner', 'Dependents', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'Contract', 'PaperlessBilling', 'PaymentMethod']
num_factors = ['tenure', 'MonthlyCharges', 'TotalCharges']

# Dropna
X=X.dropna()
# One-hot encode multi-category vars (e.g., Contract, PaymentMethod)
X_encoded = pd.get_dummies(X, columns=cat_factors, drop_first=True) # Encoded features

#print(X_encoded)

# X_test_final_set, y_test_final_set --> they will be used for final testing and model evaluation
X_train,X_test_final_set, y_train, y_test_final_set=train_test_split(X_encoded,y, test_size=0.2, random_state=42, stratify=y,shuffle=True)


# Dividing X_train,y_train into actual training set and development test set
X_train_actual,X_test_dev_set, y_train_actual, y_test_dev_set=train_test_split(X_train,y_train, test_size=0.2, random_state=42, stratify=y_train,shuffle=True)


X_train_actual.isnull().sum()
X_train_actual

from sklearn.preprocessing import StandardScaler


scaler = StandardScaler()

# Fit and transform the training data
X_train_scaled = scaler.fit_transform(X_train_actual)
X_test_dev_set_scaled=scaler.transform(X_test_dev_set) # Use this at development stage
X_test_final_set_scaled=scaler.transform(X_test_final_set)  # Use this for final evaluation

# Lets see changing the number of trials changes the outcomes or not
import optuna
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from xgboost import XGBClassifier
from sklearn.model_selection import cross_val_score

# Define the objective function
def objective(trial):
    # Suggest a model type
    model_name = trial.suggest_categorical("model", ["RandomForestClassifier", "LogisticRegression", "XGBClassifier"])

    # Hyperparameter tuning for RandomForestClassifier
    if model_name == "RandomForestClassifier":
        n_estimators = trial.suggest_int("n_estimators", 100, 200)
        max_depth = trial.suggest_int("max_depth", 5, 10)
        min_samples_leaf = trial.suggest_int("min_samples_leaf", 5, 15)

        model = RandomForestClassifier(
            n_estimators=n_estimators,
            max_depth=max_depth,
            min_samples_leaf=min_samples_leaf,
            random_state=50
        )

    # Hyperparameter tuning for LogisticRegression
    elif model_name == "LogisticRegression":
        C = trial.suggest_float("C", 0.01, 10, log=True)
        penalty = trial.suggest_categorical("penalty", ["l1", "l2", "elasticnet"])
        solver = trial.suggest_categorical("solver", ["newton-cg", "lbfgs", "liblinear", "sag", "saga"])
        class_weight = trial.suggest_categorical("class_weight", ["balanced", None])

        # Ensure the penalty and solver combination is valid
        if penalty == "l1" and solver not in ["liblinear", "saga"]:
            return float("-inf")  # Skip invalid combinations
        if penalty == "elasticnet" and solver != "saga":
            return float("-inf")  # Skip invalid combinations

        model = LogisticRegression(
            C=C,
            penalty=penalty,
            solver=solver,
            class_weight=class_weight,
            random_state=50,
            max_iter=1000
        )

    # Hyperparameter tuning for XGBClassifier
    elif model_name == "XGBClassifier":
        n_estimators = trial.suggest_int("n_estimators", 100, 200)
        max_depth = trial.suggest_int("max_depth", 5, 10)
        min_child_weight = trial.suggest_int("min_child_weight", 1, 10)
        gamma = trial.suggest_float("gamma", 0, 5)
        subsample = trial.suggest_float("subsample", 0.5, 1.0)

        model = XGBClassifier(
            n_estimators=n_estimators,
            max_depth=max_depth,
            min_child_weight=min_child_weight,
            gamma=gamma,
            subsample=subsample,
            random_state=50
        )

    # Evaluate the model using cross-validation
    try:
        score = cross_val_score(model, X_train_scaled, y_train_actual, cv=4, scoring="recall", error_score='raise').mean()
    except ValueError as e:
        # Handle model misconfiguration gracefully
        score = float("-inf")

    return score

# Create the study
study = optuna.create_study(direction="maximize", sampler=optuna.samplers.TPESampler(seed=50))
study.optimize(objective, n_trials=50)

# Print the best result
print("Best trial:")
print(study.best_trial.params)  # Suggest that logisticregression is the best algorithm for the churn dataset.
print(study.best_trial.value)

# Lets see changing the number of trials changes the outcomes or not
import optuna
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from xgboost import XGBClassifier
from sklearn.model_selection import cross_val_score

# Define the objective function
def objective(trial):
    # Suggest a model type
    model_name = trial.suggest_categorical("model", ["RandomForestClassifier", "LogisticRegression", "XGBClassifier"])

    # Hyperparameter tuning for RandomForestClassifier
    if model_name == "RandomForestClassifier":
        n_estimators = trial.suggest_int("n_estimators", 100, 200)
        max_depth = trial.suggest_int("max_depth", 5, 10)
        min_samples_leaf = trial.suggest_int("min_samples_leaf", 5, 15)

        model = RandomForestClassifier(
            n_estimators=n_estimators,
            max_depth=max_depth,
            min_samples_leaf=min_samples_leaf,
            random_state=50
        )

    # Hyperparameter tuning for LogisticRegression
    elif model_name == "LogisticRegression":
        C = trial.suggest_float("C", 0.01, 10, log=True)
        penalty = trial.suggest_categorical("penalty", ["l1", "l2", "elasticnet"])
        solver = trial.suggest_categorical("solver", ["newton-cg", "lbfgs", "liblinear", "sag", "saga"])
        class_weight = trial.suggest_categorical("class_weight", ["balanced", None])

        # Ensure the penalty and solver combination is valid
        if penalty == "l1" and solver not in ["liblinear", "saga"]:
            return float("-inf")  # Skip invalid combinations
        if penalty == "elasticnet" and solver != "saga":
            return float("-inf")  # Skip invalid combinations

        model = LogisticRegression(
            C=C,
            penalty=penalty,
            solver=solver,
            class_weight=class_weight,
            random_state=50,
            max_iter=1000
        )

    # Hyperparameter tuning for XGBClassifier
    elif model_name == "XGBClassifier":
        n_estimators = trial.suggest_int("n_estimators", 100, 200)
        max_depth = trial.suggest_int("max_depth", 5, 10)
        min_child_weight = trial.suggest_int("min_child_weight", 1, 10)
        gamma = trial.suggest_float("gamma", 0, 5)
        subsample = trial.suggest_float("subsample", 0.5, 1.0)

        model = XGBClassifier(
            n_estimators=n_estimators,
            max_depth=max_depth,
            min_child_weight=min_child_weight,
            gamma=gamma,
            subsample=subsample,
            random_state=50
        )

    # Evaluate the model using cross-validation
    try:
        score = cross_val_score(model, X_train_scaled, y_train_actual, cv=4, scoring="recall", error_score='raise').mean()
    except ValueError as e:
        # Handle model misconfiguration gracefully
        score = float("-inf")

    return score

# Create the study
study = optuna.create_study(direction="maximize", sampler=optuna.samplers.TPESampler(seed=50))
study.optimize(objective, n_trials=150)

# Print the best result
print("Best trial:")
print(study.best_trial.params)  # Suggest that logisticregression is the best algorithm for the churn dataset.
print(study.best_trial.value)

from optuna.visualization import plot_optimization_history
plot_optimization_history(study).show()

# Lets see changing the number of trials changes the outcomes or not
import optuna
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from xgboost import XGBClassifier
from sklearn.model_selection import cross_val_score

# Define the objective function
def objective(trial):
    # Suggest a model type
    model_name = trial.suggest_categorical("model", ["RandomForestClassifier", "LogisticRegression", "XGBClassifier"])

    # Hyperparameter tuning for RandomForestClassifier
    if model_name == "RandomForestClassifier":
        n_estimators = trial.suggest_int("n_estimators", 100, 200)
        max_depth = trial.suggest_int("max_depth", 5, 10)
        min_samples_leaf = trial.suggest_int("min_samples_leaf", 5, 15)

        model = RandomForestClassifier(
            n_estimators=n_estimators,
            max_depth=max_depth,
            min_samples_leaf=min_samples_leaf,
            random_state=50
        )

    # Hyperparameter tuning for LogisticRegression
    elif model_name == "LogisticRegression":
        C = trial.suggest_float("C", 0.01, 10, log=True)
        penalty = trial.suggest_categorical("penalty", ["l1", "l2", "elasticnet"])
        solver = trial.suggest_categorical("solver", ["newton-cg", "lbfgs", "liblinear", "sag", "saga"])
        class_weight = trial.suggest_categorical("class_weight", ["balanced", None])

        # Ensure the penalty and solver combination is valid
        if penalty == "l1" and solver not in ["liblinear", "saga"]:
            return float("-inf")  # Skip invalid combinations
        if penalty == "elasticnet" and solver != "saga":
            return float("-inf")  # Skip invalid combinations

        model = LogisticRegression(
            C=C,
            penalty=penalty,
            solver=solver,
            class_weight=class_weight,
            random_state=50,
            max_iter=1000
        )

    # Hyperparameter tuning for XGBClassifier
    elif model_name == "XGBClassifier":
        n_estimators = trial.suggest_int("n_estimators", 100, 200)
        max_depth = trial.suggest_int("max_depth", 5, 10)
        min_child_weight = trial.suggest_int("min_child_weight", 1, 10)
        gamma = trial.suggest_float("gamma", 0, 5)
        subsample = trial.suggest_float("subsample", 0.5, 1.0)

        model = XGBClassifier(
            n_estimators=n_estimators,
            max_depth=max_depth,
            min_child_weight=min_child_weight,
            gamma=gamma,
            subsample=subsample,
            random_state=50
        )

    # Evaluate the model using cross-validation
    try:
        score = cross_val_score(model, X_train_scaled, y_train_actual, cv=4, scoring="recall", error_score='raise').mean()
    except ValueError as e:
        # Handle model misconfiguration gracefully
        score = float("-inf")

    return score

# Create the study
study = optuna.create_study(direction="maximize", sampler=optuna.samplers.TPESampler(seed=50))
study.optimize(objective, n_trials=200)

# Print the best result
print("Best trial:")
print(study.best_trial.params)  # Suggest that logisticregression is the best algorithm for the churn dataset.
print(study.best_trial.value)

from optuna.visualization import plot_optimization_history
plot_optimization_history(study).show()

# Lets see changing the number of trials changes the outcomes or not
import optuna
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from xgboost import XGBClassifier
from sklearn.model_selection import cross_val_score

# Define the objective function
def objective(trial):
    # Suggest a model type
    model_name = trial.suggest_categorical("model", ["RandomForestClassifier", "LogisticRegression", "XGBClassifier"])

    # Hyperparameter tuning for RandomForestClassifier
    if model_name == "RandomForestClassifier":
        n_estimators = trial.suggest_int("n_estimators", 100, 200)
        max_depth = trial.suggest_int("max_depth", 5, 10)
        min_samples_leaf = trial.suggest_int("min_samples_leaf", 5, 15)

        model = RandomForestClassifier(
            n_estimators=n_estimators,
            max_depth=max_depth,
            min_samples_leaf=min_samples_leaf,
            random_state=50
        )

    # Hyperparameter tuning for LogisticRegression
    elif model_name == "LogisticRegression":
        C = trial.suggest_float("C", 0.01, 10, log=True)
        penalty = trial.suggest_categorical("penalty", ["l1", "l2", "elasticnet"])
        solver = trial.suggest_categorical("solver", ["newton-cg", "lbfgs", "liblinear", "sag", "saga"])
        class_weight = trial.suggest_categorical("class_weight", ["balanced", None])

        # Ensure the penalty and solver combination is valid
        if penalty == "l1" and solver not in ["liblinear", "saga"]:
            return float("-inf")  # Skip invalid combinations
        if penalty == "elasticnet" and solver != "saga":
            return float("-inf")  # Skip invalid combinations

        model = LogisticRegression(
            C=C,
            penalty=penalty,
            solver=solver,
            class_weight=class_weight,
            random_state=50,
            max_iter=1000
        )

    # Hyperparameter tuning for XGBClassifier
    elif model_name == "XGBClassifier":
        n_estimators = trial.suggest_int("n_estimators", 100, 200)
        max_depth = trial.suggest_int("max_depth", 5, 10)
        min_child_weight = trial.suggest_int("min_child_weight", 1, 10)
        gamma = trial.suggest_float("gamma", 0, 5)
        subsample = trial.suggest_float("subsample", 0.5, 1.0)

        model = XGBClassifier(
            n_estimators=n_estimators,
            max_depth=max_depth,
            min_child_weight=min_child_weight,
            gamma=gamma,
            subsample=subsample,
            random_state=50
        )

    # Evaluate the model using cross-validation
    try:
        score = cross_val_score(model, X_train_scaled, y_train_actual, cv=4, scoring="recall", error_score='raise').mean()
    except ValueError as e:
        # Handle model misconfiguration gracefully
        score = float("-inf")

    return score

# Create the study
study = optuna.create_study(direction="maximize", sampler=optuna.samplers.TPESampler(seed=50))
study.optimize(objective, n_trials=250)

# Print the best result
print("Best trial:")
print(study.best_trial.params)  # Suggest that logisticregression is the best algorithm for the churn dataset.
print(study.best_trial.value)

from optuna.visualization import plot_optimization_history
plot_optimization_history(study).show()

# Lets see changing the number of trials changes the outcomes or not
import optuna
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from xgboost import XGBClassifier
from sklearn.model_selection import cross_val_score

# Define the objective function
def objective(trial):
    # Suggest a model type
    model_name = trial.suggest_categorical("model", ["RandomForestClassifier", "LogisticRegression", "XGBClassifier"])

    # Hyperparameter tuning for RandomForestClassifier
    if model_name == "RandomForestClassifier":
        n_estimators = trial.suggest_int("n_estimators", 100, 200)
        max_depth = trial.suggest_int("max_depth", 5, 10)
        min_samples_leaf = trial.suggest_int("min_samples_leaf", 5, 15)

        model = RandomForestClassifier(
            n_estimators=n_estimators,
            max_depth=max_depth,
            min_samples_leaf=min_samples_leaf,
            random_state=50
        )

    # Hyperparameter tuning for LogisticRegression
    elif model_name == "LogisticRegression":
        C = trial.suggest_float("C", 0.01, 10, log=True)
        penalty = trial.suggest_categorical("penalty", ["l1", "l2", "elasticnet"])
        solver = trial.suggest_categorical("solver", ["newton-cg", "lbfgs", "liblinear", "sag", "saga"])
        class_weight = trial.suggest_categorical("class_weight", ["balanced", None])

        # Ensure the penalty and solver combination is valid
        if penalty == "l1" and solver not in ["liblinear", "saga"]:
            return float("-inf")  # Skip invalid combinations
        if penalty == "elasticnet" and solver != "saga":
            return float("-inf")  # Skip invalid combinations

        model = LogisticRegression(
            C=C,
            penalty=penalty,
            solver=solver,
            class_weight=class_weight,
            random_state=50,
            max_iter=1000
        )

    # Hyperparameter tuning for XGBClassifier
    elif model_name == "XGBClassifier":
        n_estimators = trial.suggest_int("n_estimators", 100, 200)
        max_depth = trial.suggest_int("max_depth", 5, 10)
        min_child_weight = trial.suggest_int("min_child_weight", 1, 10)
        gamma = trial.suggest_float("gamma", 0, 5)
        subsample = trial.suggest_float("subsample", 0.5, 1.0)

        model = XGBClassifier(
            n_estimators=n_estimators,
            max_depth=max_depth,
            min_child_weight=min_child_weight,
            gamma=gamma,
            subsample=subsample,
            random_state=50
        )

    # Evaluate the model using cross-validation
    try:
        score = cross_val_score(model, X_train_scaled, y_train_actual, cv=4, scoring="recall", error_score='raise').mean()
    except ValueError as e:
        # Handle model misconfiguration gracefully
        score = float("-inf")

    return score

# Create the study
study = optuna.create_study(direction="maximize", sampler=optuna.samplers.TPESampler(seed=50))
study.optimize(objective, n_trials=300)

# Print the best result
print("Best trial:")
print(study.best_trial.params)  # Suggest that logisticregression is the best algorithm for the churn dataset.
print(study.best_trial.value)

from optuna.visualization import plot_optimization_history
plot_optimization_history(study).show()

# Lets see changing the number of trials changes the outcomes or not
import optuna
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from xgboost import XGBClassifier
from sklearn.model_selection import cross_val_score

# Define the objective function
def objective(trial):
    # Suggest a model type
    model_name = trial.suggest_categorical("model", ["RandomForestClassifier", "LogisticRegression", "XGBClassifier"])

    # Hyperparameter tuning for RandomForestClassifier
    if model_name == "RandomForestClassifier":
        n_estimators = trial.suggest_int("n_estimators", 100, 200)
        max_depth = trial.suggest_int("max_depth", 5, 10)
        min_samples_leaf = trial.suggest_int("min_samples_leaf", 5, 15)

        model = RandomForestClassifier(
            n_estimators=n_estimators,
            max_depth=max_depth,
            min_samples_leaf=min_samples_leaf,
            random_state=50
        )

    # Hyperparameter tuning for LogisticRegression
    elif model_name == "LogisticRegression":
        C = trial.suggest_float("C", 0.01, 10, log=True)
        penalty = trial.suggest_categorical("penalty", ["l1", "l2", "elasticnet"])
        solver = trial.suggest_categorical("solver", ["newton-cg", "lbfgs", "liblinear", "sag", "saga"])
        class_weight = trial.suggest_categorical("class_weight", ["balanced", None])

        # Ensure the penalty and solver combination is valid
        if penalty == "l1" and solver not in ["liblinear", "saga"]:
            return float("-inf")  # Skip invalid combinations
        if penalty == "elasticnet" and solver != "saga":
            return float("-inf")  # Skip invalid combinations

        model = LogisticRegression(
            C=C,
            penalty=penalty,
            solver=solver,
            class_weight=class_weight,
            random_state=50,
            max_iter=1000
        )

    # Hyperparameter tuning for XGBClassifier
    elif model_name == "XGBClassifier":
        n_estimators = trial.suggest_int("n_estimators", 100, 200)
        max_depth = trial.suggest_int("max_depth", 5, 10)
        min_child_weight = trial.suggest_int("min_child_weight", 1, 10)
        gamma = trial.suggest_float("gamma", 0, 5)
        subsample = trial.suggest_float("subsample", 0.5, 1.0)

        model = XGBClassifier(
            n_estimators=n_estimators,
            max_depth=max_depth,
            min_child_weight=min_child_weight,
            gamma=gamma,
            subsample=subsample,
            random_state=50
        )

    # Evaluate the model using cross-validation
    try:
        score = cross_val_score(model, X_train_scaled, y_train_actual, cv=4, scoring="recall", error_score='raise').mean()
    except ValueError as e:
        # Handle model misconfiguration gracefully
        score = float("-inf")

    return score

# Create the study
study = optuna.create_study(direction="maximize", sampler=optuna.samplers.TPESampler(seed=50))
study.optimize(objective, n_trials=350)

# Print the best result
print("Best trial:")
print(study.best_trial.params)  # Suggest that logisticregression is the best algorithm for the churn dataset.
print(study.best_trial.value)

from optuna.visualization import plot_optimization_history
plot_optimization_history(study).show()

# Lets see changing the number of trials changes the outcomes or not
import optuna
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from xgboost import XGBClassifier
from sklearn.model_selection import cross_val_score

# Define the objective function
def objective(trial):
    # Suggest a model type
    model_name = trial.suggest_categorical("model", ["RandomForestClassifier", "LogisticRegression", "XGBClassifier"])

    # Hyperparameter tuning for RandomForestClassifier
    if model_name == "RandomForestClassifier":
        n_estimators = trial.suggest_int("n_estimators", 100, 200)
        max_depth = trial.suggest_int("max_depth", 5, 10)
        min_samples_leaf = trial.suggest_int("min_samples_leaf", 5, 15)

        model = RandomForestClassifier(
            n_estimators=n_estimators,
            max_depth=max_depth,
            min_samples_leaf=min_samples_leaf,
            random_state=50
        )

    # Hyperparameter tuning for LogisticRegression
    elif model_name == "LogisticRegression":
        C = trial.suggest_float("C", 0.01, 10, log=True)
        penalty = trial.suggest_categorical("penalty", ["l1", "l2", "elasticnet"])
        solver = trial.suggest_categorical("solver", ["newton-cg", "lbfgs", "liblinear", "sag", "saga"])
        class_weight = trial.suggest_categorical("class_weight", ["balanced", None])

        # Ensure the penalty and solver combination is valid
        if penalty == "l1" and solver not in ["liblinear", "saga"]:
            return float("-inf")  # Skip invalid combinations
        if penalty == "elasticnet" and solver != "saga":
            return float("-inf")  # Skip invalid combinations

        model = LogisticRegression(
            C=C,
            penalty=penalty,
            solver=solver,
            class_weight=class_weight,
            random_state=50,
            max_iter=1000
        )

    # Hyperparameter tuning for XGBClassifier
    elif model_name == "XGBClassifier":
        n_estimators = trial.suggest_int("n_estimators", 100, 200)
        max_depth = trial.suggest_int("max_depth", 5, 10)
        min_child_weight = trial.suggest_int("min_child_weight", 1, 10)
        gamma = trial.suggest_float("gamma", 0, 5)
        subsample = trial.suggest_float("subsample", 0.5, 1.0)

        model = XGBClassifier(
            n_estimators=n_estimators,
            max_depth=max_depth,
            min_child_weight=min_child_weight,
            gamma=gamma,
            subsample=subsample,
            random_state=50
        )

    # Evaluate the model using cross-validation
    try:
        score = cross_val_score(model, X_train_scaled, y_train_actual, cv=4, scoring="recall", error_score='raise').mean()
    except ValueError as e:
        # Handle model misconfiguration gracefully
        score = float("-inf")

    return score

# Create the study
study = optuna.create_study(direction="maximize", sampler=optuna.samplers.TPESampler(seed=50))
study.optimize(objective, n_trials=400)

# Print the best result
print("Best trial:")
print(study.best_trial.params)  # Suggest that logisticregression is the best algorithm for the churn dataset.
print(study.best_trial.value)

from optuna.visualization import plot_optimization_history
plot_optimization_history(study).show()

# Lets see changing the number of trials changes the outcomes or not
import optuna
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from xgboost import XGBClassifier
from sklearn.model_selection import cross_val_score

# Define the objective function
def objective(trial):
    # Suggest a model type
    model_name = trial.suggest_categorical("model", ["RandomForestClassifier", "LogisticRegression", "XGBClassifier"])

    # Hyperparameter tuning for RandomForestClassifier
    if model_name == "RandomForestClassifier":
        n_estimators = trial.suggest_int("n_estimators", 100, 200)
        max_depth = trial.suggest_int("max_depth", 5, 10)
        min_samples_leaf = trial.suggest_int("min_samples_leaf", 5, 15)

        model = RandomForestClassifier(
            n_estimators=n_estimators,
            max_depth=max_depth,
            min_samples_leaf=min_samples_leaf,
            random_state=50
        )

    # Hyperparameter tuning for LogisticRegression
    elif model_name == "LogisticRegression":
        C = trial.suggest_float("C", 0.01, 10, log=True)
        penalty = trial.suggest_categorical("penalty", ["l1", "l2", "elasticnet"])
        solver = trial.suggest_categorical("solver", ["newton-cg", "lbfgs", "liblinear", "sag", "saga"])
        class_weight = trial.suggest_categorical("class_weight", ["balanced", None])

        # Ensure the penalty and solver combination is valid
        if penalty == "l1" and solver not in ["liblinear", "saga"]:
            return float("-inf")  # Skip invalid combinations
        if penalty == "elasticnet" and solver != "saga":
            return float("-inf")  # Skip invalid combinations

        model = LogisticRegression(
            C=C,
            penalty=penalty,
            solver=solver,
            class_weight=class_weight,
            random_state=50,
            max_iter=1000
        )

    # Hyperparameter tuning for XGBClassifier
    elif model_name == "XGBClassifier":
        n_estimators = trial.suggest_int("n_estimators", 100, 200)
        max_depth = trial.suggest_int("max_depth", 5, 10)
        min_child_weight = trial.suggest_int("min_child_weight", 1, 10)
        gamma = trial.suggest_float("gamma", 0, 5)
        subsample = trial.suggest_float("subsample", 0.5, 1.0)

        model = XGBClassifier(
            n_estimators=n_estimators,
            max_depth=max_depth,
            min_child_weight=min_child_weight,
            gamma=gamma,
            subsample=subsample,
            random_state=50
        )

    # Evaluate the model using cross-validation
    try:
        score = cross_val_score(model, X_train_scaled, y_train_actual, cv=4, scoring="recall", error_score='raise').mean()
    except ValueError as e:
        # Handle model misconfiguration gracefully
        score = float("-inf")

    return score

# Create the study
study = optuna.create_study(direction="maximize", sampler=optuna.samplers.TPESampler(seed=50))
study.optimize(objective, n_trials=450)

# Print the best result
print("Best trial:")
print(study.best_trial.params)  # Suggest that logisticregression is the best algorithm for the churn dataset.
print(study.best_trial.value)

from optuna.visualization import plot_optimization_history
plot_optimization_history(study).show()

"""The recall score did not increase after 350 trials."""